# -*- coding: utf-8 -*-
"""Assignment_6_Hybrid_Momentum.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eUijeZ6llzZViOeTSGL1WOvXvnQ5WqVB

# Assignment 3

### Setup
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from plotnine import *
import random

import seaborn as sn
import matplotlib.pyplot as plt

import yfinance as yf

from datetime import date
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from scipy.stats import norm
from scipy.stats import linregress
import itertools
from scipy.optimize import minimize

My_Portfolio_X = pd.read_csv('BBG_data_2024.csv')

My_Portfolio_X

My_Portfolio_X.iloc[1, :] = My_Portfolio_X.iloc[1, :].fillna(method='ffill')

for col in My_Portfolio_X.columns:
    My_Portfolio_X.loc[3, col] = str(My_Portfolio_X.iloc[1][col]) + " " + str(My_Portfolio_X.loc[3, col])

My_Portfolio_X = My_Portfolio_X.iloc[3:].reset_index(drop=True)

My_Portfolio_X.columns = My_Portfolio_X.iloc[0]

My_Portfolio_X = My_Portfolio_X.drop(0)

My_Portfolio_X = My_Portfolio_X.rename(columns={'nan Dates': 'Dates'})

My_Portfolio_X

print(My_Portfolio_X.isnull().sum())

My_Portfolio_X['Dates'] = pd.to_datetime(My_Portfolio_X['Dates'])

My_Portfolio_X.sort_values(by='Dates', ascending=True, inplace=True)

My_Portfolio_X

"""### Filtering Data"""

sp500_tickers = [col for col in My_Portfolio_X.columns if 'UN Equity' in col]
filtered_data = My_Portfolio_X[['Dates'] + [col for col in My_Portfolio_X.columns if 'PX_LAST' in col]].copy()

filtered_data['Dates'] = pd.to_datetime(filtered_data['Dates'])
filtered_data.set_index('Dates', inplace=True)

filtered_data

close_price_data = filtered_data

"""##Secondary Data"""

# Load the data from the uploaded Excel file
file_path = 'VIX_Data.xlsx'
data = pd.read_excel(file_path)

# Display the first few rows of the dataframe and the column names to understand its structure
data.head(), data.columns
# Sort data by date just in case it's not in order
data.sort_values('Date', inplace=True)


# Compute the 'leverage_multiple'
data['leverage_multiple'] = 1.0  # Default value

# Initialize variables to track the last intersection's value
last_leverage = 1.0

# Iterate through the DataFrame to adjust 'leverage_multiple' based on the specified condition
for i in range(1, len(data)):
    previous_close_above_ma = data.loc[i-1, 'Close'] > data.loc[i-1, '50 day MA']
    current_close_below_ma = data.loc[i, 'Close'] < data.loc[i, '50 day MA']
    previous_close_below_ma = data.loc[i-1, 'Close'] < data.loc[i-1, '50 day MA']
    current_close_above_ma = data.loc[i, 'Close'] > data.loc[i, '50 day MA']

    # Check for crossing from above to below
    if previous_close_above_ma and current_close_below_ma:
        data.loc[i, 'leverage_multiple'] = 1.6
        last_leverage = 1.6
    # Check for crossing from below to above
    elif previous_close_below_ma and current_close_above_ma:
        data.loc[i, 'leverage_multiple'] = 1
        last_leverage = 1
    else:
        data.loc[i, 'leverage_multiple'] = last_leverage  # Carry forward the last value

data.rename(columns = {'Date':'Dates'}, inplace=True)

# # Display the first few rows to check the implementation
# data.head()
data.to_csv('Modified_VIX_Data.csv', index=False)
# Modified_VIX_Data['Date'] = pd.to_datetime(Modified_VIX_Data['Date'])

# Display the first few rows to check the implementation
data.head()
#data.to_csv('Modified_VIX_Data.csv', index=False)
Modified_VIX_Data = pd.read_csv("Modified_VIX_Data.csv")
Modified_VIX_Data['Dates'] = pd.to_datetime(Modified_VIX_Data['Dates'])
Modified_VIX_Data.rename(columns = {'Date':'Dates'}, inplace=True)

Modified_VIX_Data

"""### Calculating 6-Month Momentum"""

filtered_data = filtered_data.apply(pd.to_numeric, errors='coerce')

original_columns = filtered_data.columns

for column in original_columns:
  filtered_data[column + " 6_Month_Momentum"] = filtered_data[column].pct_change(126) * 100

filtered_data

original_momentum_columns = original_columns + ' 6_Month_Momentum'
original_momentum_columns

"""### Calculating Daily Pct Change in 6 Month Momentum"""

for column in original_momentum_columns:
  filtered_data[column + " Daily Change"] = filtered_data[column].pct_change() * 100

filtered_data

pct_change_momentum_columns = original_momentum_columns + ' Daily Change'
pct_change_momentum_columns

"""### Calculating 30 Day Moving Avg of Pct Change in 6 Month Momentum"""

for column in pct_change_momentum_columns:
  filtered_data[column + " 30_day_MovAvg"] = filtered_data[column].rolling(window=30).mean()

filtered_data

filtered_data.columns

"""### Calculating Weighted Momentum Factor"""

for column in original_columns:
  filtered_data[column + " Weighted Momentum"] = ((filtered_data[column + ' 6_Month_Momentum Daily Change']) * 0.7) + ((filtered_data[column + ' 6_Month_Momentum Daily Change 30_day_MovAvg']) * 0.3)

filtered_data

weighted_momentum_data = pd.DataFrame()

for column in original_columns:
  weighted_momentum_data[column + ' Weighted Momentum'] = filtered_data[column + " Weighted Momentum"]

weighted_momentum_data

weighted_momentum_data

"""### Top and Bottom 20"""

def get_top_20_columns(row):
    return [col.split()[0] for col in row.nlargest(20).index.tolist()]

def get_bottom_20_columns(row):
    return [col.split()[0] for col in row.nsmallest(20).index.tolist()]

weighted_momentum_long = weighted_momentum_data.apply(get_top_20_columns, axis=1, result_type='expand')
weighted_momentum_short = weighted_momentum_data.apply(get_bottom_20_columns, axis=1, result_type='expand')

weighted_momentum_long.columns = [f'top_{i+1}' for i in range(20)]
weighted_momentum_short.columns = [f'bottom_{i+1}' for i in range(20)]

weighted_momentum_long

weighted_momentum_short

close_price_data

close_price_columns = close_price_data.columns
close_price_columns

for column in close_price_columns:
  close_price_data[column] = pd.to_numeric(close_price_data[column], errors="coerce")  # Convert column to numeric
  close_price_data[column + " Daily Change"] = close_price_data[column].pct_change() * 100

# for column in close_price_columns:
#   close_price_data[column + " Daily Change"] = close_price_data[column].pct_change() * 100

close_price_data

"""### Factor Portfolio Elements to Check"""

close_price_data

Price_and_Weighted_Momentum = close_price_data.join(weighted_momentum_data)

Price_and_Weighted_Momentum

Price_and_Weighted_Momentum

Price_and_Weighted_Momentum.reset_index(inplace=True)
Price_and_Weighted_Momentum['Dates'] = pd.to_datetime(Price_and_Weighted_Momentum['Dates'])

Price_and_Weighted_Momentum

Price_and_Weighted_Momentum.columns

rebalancing_dates = []

for _, row in Price_and_Weighted_Momentum.iterrows():
    if row['Dates'].month in [3, 6, 9, 12] and row['Dates'].day == 1:
        if row['Dates'].weekday() < 5:
            rebalancing_dates.append(row['Dates'])
        else:
            next_business_day = row['Dates'] + BDay(1)
            rebalancing_dates.append(next_business_day)

rebalancing_dates = pd.Series(rebalancing_dates).drop_duplicates().sort_values()

rebalancing_dates

momentum_columns = weighted_momentum_data.columns

price_columns = close_price_data.columns

"""### Momentum Factor Portfolio"""

Price_and_Weighted_Momentum

price_df = Price_and_Weighted_Momentum[price_columns]
momentum_df = Price_and_Weighted_Momentum[momentum_columns]

price_df.columns = [col.replace(' PX_LAST', '') for col in price_columns]
momentum_df.columns = [col.replace(' PX_LAST Weighted Momentum', '') for col in momentum_columns]

price_returns = price_df.pct_change()
price_returns.to_csv("cumulative_Returns.csv")

momentum_ranking = momentum_df.rank(axis=1, ascending=False)
long_positions = momentum_ranking <= 10   # top 10 momentum
short_positions = momentum_ranking > (len(momentum_df.columns) - 10)  # bottom 10 momentum

long_positions
long_positions_column = long_positions.columns
short_positions_column = short_positions.columns

price_returns["Dates"] = Price_and_Weighted_Momentum["Dates"]

price_returns

Modified_VIX_Data['Dates'] = pd.to_datetime(Modified_VIX_Data['Dates'])
price_returns['Dates'] = pd.to_datetime(price_returns['Dates'])

# Perform an inner join on the 'Date' column
merged_price_results = pd.merge(Modified_VIX_Data, price_returns, on='Dates', how='inner')

merged_price_results

portfolio_returns = price_returns.copy()

# Iterate over the columns and apply the leverage multiple
for column in long_positions_column:
    # Apply leverage to long positions
    portfolio_returns[column] = price_returns[column] * (merged_price_results['leverage_multiple'] / 20)

for column in short_positions_column:
    # Apply leverage to short positions
    portfolio_returns[column] = price_returns[column] * (merged_price_results['leverage_multiple'] / 20)

# Sum the returns for long positions and short positions separately across columns (axis=1)
daily_long_returns = portfolio_returns[long_positions_column].sum(axis=1)
daily_short_returns = portfolio_returns[short_positions_column].sum(axis=1)

# Calculate daily portfolio returns by adding long and short returns
daily_portfolio_returns = daily_long_returns + daily_short_returns

daily_portfolio_returns

daily_port_return_df = pd.DataFrame(daily_portfolio_returns)

daily_port_return_df

daily_port_return_df['Log Daily Returns'] = np.log(1 + daily_port_return_df[0])

daily_port_return_df

daily_portfolio_returns

momentum_port_daily_returns = pd.DataFrame(daily_portfolio_returns)
momentum_port_daily_returns['Dates'] = Price_and_Weighted_Momentum['Dates']
momentum_port_daily_returns

momentum_port_daily_returns[0].mean()

daily_returns = momentum_port_daily_returns[0]
dates = momentum_port_daily_returns['Dates']

momentum_port_cum_returns = pd.DataFrame({
    'Daily Returns': daily_returns,
    'Dates': dates
})

momentum_port_cum_returns

momentum_port_cum_returns['Cumulative Returns'] = momentum_port_cum_returns['Daily Returns'].cumsum()

print(momentum_port_cum_returns)

# Convert 'Dates' to datetime type for better plotting.
momentum_port_cum_returns['Dates'] = pd.to_datetime(momentum_port_cum_returns['Dates'])

# Plotting
plt.figure(figsize=(10, 5))  # Set the figure size (width, height in inches).
plt.plot(momentum_port_cum_returns['Dates'], momentum_port_cum_returns['Cumulative Returns'], linewidth=1)  # Adjust linewidth to make the line thinner

# Adding title and labels
plt.title('Cumulative Returns Over Time')
plt.xlabel('Date')
plt.ylabel('Cumulative Returns')

# Rotate date labels for better readability
plt.xticks(rotation=45)
plt.grid(True)  # Add grid for better readability of the plot

# Show the plot
plt.show()

#cumulative to daily returns

momentum_port_returns = pd.DataFrame({
    'Daily Returns': daily_returns,
    'Dates': dates
})

momentum_port_returns

momentum_port_returns2 = momentum_port_returns.iloc[1:]

# Initialize the initial portfolio value
initial_value = 100
portfolio_values = [initial_value]  # Use consistent naming for your list

# Compute portfolio value for each day
for value in momentum_port_returns['Daily Returns']:
    new_value = portfolio_values[-1] * (1 + value/100)  # Correctly refer to the last element in the list
    portfolio_values.append(new_value)

# Remove the first element as it is the initial value repeated
portfolio_values = portfolio_values[1:]

# Append the computed portfolio values to the DataFrame
momentum_port_returns['Portfolio Value'] = portfolio_values

# Display the updated DataFrame
print(momentum_port_returns)

# Plotting
plt.figure(figsize=(10, 5))
plt.plot(momentum_port_returns['Dates'], momentum_port_returns['Portfolio Value'], linestyle='-')
plt.title('Hypothetical Growth of $100')
plt.xlabel('Date')
plt.ylabel('Portfolio Value')
plt.grid(True)
plt.show()